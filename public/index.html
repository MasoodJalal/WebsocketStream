<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>ðŸŽ¤ Live Echo</title>
  <style>
    body {
      font-family: -apple-system, BlinkMacSystemFont, sans-serif;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      min-height: 100vh;
      margin: 0;
      background: #f8f9fa;
    }
    h1 { color: #333; margin-bottom: 1rem; }
    #status {
      margin: 1rem 0;
      padding: 0.75rem 1.5rem;
      background: #e9ecef;
      border-radius: 8px;
      min-width: 300px;
      text-align: center;
    }
    button {
      padding: 0.75rem 2rem;
      font-size: 1.1rem;
      background: #28a745;
      color: white;
      border: none;
      border-radius: 6px;
      cursor: pointer;
      transition: background 0.2s;
    }
    button:hover { background: #218838; }
    button:disabled { background: #ccc; cursor: not-allowed; }
  </style>
</head>
<body>
  <h1>ðŸŽ¤ Speak & Hear Echo</h1>
  <button id="startBtn">Start Echo</button>
  <div id="status">Click to start mic</div>

  <script>
    let socket = null;
    let audioContext = null;
    let mediaStream = null;
    let sourceNode = null;
    let scriptProcessor = null;

    const SAMPLE_RATE = 44100;
    const BUFFER_SIZE = 4096; // ~93ms â€” reduce to 1024 for lower latency (~23ms)

    async function startEcho() {
      const status = document.getElementById('status');
      status.textContent = 'ðŸŽ™ï¸ Requesting mic access...';

      try {
        // 1. Get mic stream
        mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
        status.textContent = 'ðŸ“¡ Connecting to server...';

        // 2. Setup Web Audio
        audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: SAMPLE_RATE });
        if (audioContext.state === 'suspended') {
          await audioContext.resume();
        }

        // 3. Connect to WebSocket
        socket = new WebSocket(`ws://${location.host}/ws-echo`);
        socket.binaryType = 'arraybuffer';

        socket.onopen = () => {
          status.textContent = 'ðŸ” Echo active! Speak now...';
        };

        socket.onclose = () => {
          status.textContent = 'ðŸ”Œ Disconnected';
          cleanup();
        };

        socket.onerror = (err) => {
          status.textContent = 'âŒ Connection error';
          console.error(err);
          cleanup();
        };

        // 4. Play incoming audio
        socket.onmessage = (event) => {
          const int16 = new Int16Array(event.data);
          const float32 = new Float32Array(int16.length);
          for (let i = 0; i < int16.length; i++) {
            float32[i] = int16[i] / 32768.0;
          }

          // De-interleave stereo (but we send mono â†’ treat as mono)
          const length = float32.length;
          const audioBuffer = audioContext.createBuffer(1, length, SAMPLE_RATE);
          audioBuffer.copyToChannel(float32, 0);

          const source = audioContext.createBufferSource();
          source.buffer = audioBuffer;
          source.connect(audioContext.destination);
          source.start();
        };

        // 5. Send mic audio to server
        sourceNode = audioContext.createMediaStreamSource(mediaStream);
        
        // Use ScriptProcessorNode (deprecated but works everywhere)
        scriptProcessor = audioContext.createScriptProcessor(BUFFER_SIZE, 1, 1);
        scriptProcessor.onaudioprocess = (event) => {
          const input = event.inputBuffer.getChannelData(0); // Mono
          const int16 = new Int16Array(input.length);
          for (let i = 0; i < input.length; i++) {
            // Clamp to [-1, 1]
            const s = Math.max(-1, Math.min(1, input[i]));
            int16[i] = s * 32767;
          }
          if (socket && socket.readyState === WebSocket.OPEN) {
            socket.send(int16.buffer);
          }
        };

        sourceNode.connect(scriptProcessor);
        scriptProcessor.connect(audioContext.destination); // optional: hear original too

      } catch (err) {
        status.textContent = 'ðŸ’¥ Error: ' + (err.message || err.name);
        console.error(err);
        cleanup();
      }
    }

    function cleanup() {
      if (mediaStream) {
        mediaStream.getTracks().forEach(track => track.stop());
        mediaStream = null;
      }
      if (scriptProcessor) {
        scriptProcessor.disconnect();
        scriptProcessor = null;
      }
      if (sourceNode) {
        sourceNode.disconnect();
        sourceNode = null;
      }
      if (socket) {
        socket.close();
        socket = null;
      }
      if (audioContext) {
        audioContext.close().catch(() => {});
        audioContext = null;
      }
    }

    document.getElementById('startBtn').onclick = startEcho;
  </script>
</body>
</html>